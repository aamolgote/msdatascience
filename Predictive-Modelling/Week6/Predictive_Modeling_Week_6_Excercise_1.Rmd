---
title: "Assignment: Chapter 8 Exercises (Week 6)"
author: "Amol Gote"
date: "08/16/2020"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(MASS)
library(boot)
library(glmnet)
library(leaps)
library(pls)
library(tree)
```

# Problem 9 This problem involves the OJ data set which is part of the ISLR package.

# 9a Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.

```{r 9a_split_data_set}
training_oj_subset <- sample(nrow(OJ), 800)
training_oj_ds = OJ[training_oj_subset, ]
test_oj_ds = OJ[-training_oj_subset, ]
nrow(training_oj_ds)
nrow(test_oj_ds)
```

  Training dataset size `r nrow(training_oj_ds)`
  
  

# 9b Fit a tree to the training data, with Purchase as the response and the other variables as predictors. Use the summary() function to produce summary statistics about the tree, and describe the results obtained. What is the training error rate? How many terminal nodes does the tree have? 

```{r 9b_fit_tree}
tree_oj <- tree(Purchase∼., OJ ,subset = training_oj_subset )
summary(tree_oj)
```

  1. Tree has 8 terminal nodes
  2. It uses 4 variables LoyalCH,PriceDiff,ListPriceDiff,DiscMM
  3. Training error rate is 0.1625

# 9c Type in the name of the tree object in order to get a detailed text output. Pick one of the terminal nodes, and interpret the information displayed.

```{r 9c_full_output}
tree_oj
```

  1. * Indicates that it is terminal node.
  2. Terminal node 24, 
    a. variable used to split us DiscMM, split is on DiscMM < 0.15
    b. There are 40 observations or records or points in this terminal node.
    c. Deviance is 48.870
    d. Prediction is for “CH”
    e. Fraction of observations in this branch that takes on values of “CH” and “MM” = (0.70000 0.30000 )


# 9d Create a plot of the tree, and interpret the results.
    
```{r 9d__plot_tree}
plot(tree_oj)
text(tree_oj, pretty=0)
```

  1. The prime indicator/factor  for Purchase appears to LoyalCH
  2. LoyalCH Values less than 0.5036 is been primarily classified as MM
  3. LoyalCH Values greater than than 0.764572 is been primarily classified as CH
  4. LoyalCH Values less than 0.764572 will be classified based on 2 factors ListPriceDiff and then DiscMM
  5. LoyalCH Values less than 0.764572 will be primarily calssified as CH with exception of ListPriceDiff < 0.235 and DISCMM > 0.15
  

# 9e. Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test error rate?

```{r 9e_full_predict_response}
prediction <- predict(tree_oj, test_oj_ds, type="class")
table(prediction, test_oj_ds$Purchase)
test_error_rate <- mean(prediction != test_oj_ds$Purchase)
test_error_rate_percentage <- test_error_rate * 100
test_error_rate_percentage
test_accuracy_rate <- mean(prediction == test_oj_ds$Purchase)
test_accuracy_rate_percentage <- test_accuracy_rate * 100
test_accuracy_rate_percentage

```
  Test error rate is `r test_error_rate` which is `r test_error_rate_percentage`%
  Test accuracy is `r test_accuracy_rate` which is `r test_accuracy_rate_percentage`%
  
  
# 9f Apply the cv.tree() function to the training set in order to determine the optimal tree size.

```{r 9f_determine_optimal_tree_size}
optimal_tree <- cv.tree(tree_oj, FUN = prune.tree)
optimal_tree
```

  Optimal tree size is 8.