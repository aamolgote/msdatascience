---
title: "Final Project"
author: "Amol Gote"
date: "08/09/2020"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

# Dataset Info
  1. For this project will be using the lending loan club dataset, located at https://www.kaggle.com/wordsforthewise/lending-club
  2. Since this datasize is huge and due to comouting constraints, will using the data for 2018 only. Only approved loans dataset will be in scope for this project. 
  3. Effective dataset size if of 495,242 observations/loans 

# About lending club
  The Lending Club is a peer-to-peer lending service (it lends money to customers by matching lenders to borrowers), based in the United States. This company enables
  borrowers to create loan listings on its website by supplying details about themselves and the loans that they would like to request.

# Dataset Attributes 
  1. Dataset contains various attributes based on which the credit lending decision takes place, this includes Debt to income ratio, annual income, home ownership type
  (Rented,Mortgage, Owned), employment details.  Dataset also contains geographical information like state and zip code. It also has issued loan details like funded Loan
  Amount, issued month and year, loan Term (36 or 60 months) and interest rate. Post loan has been issued, loan performance needs to be tracked, and this dataset
  also contains those details loan Status (Current, Paid Off, Charged Off, Delinquent), loan Grades and delinquency details. 

# Research Objectives
  1. Qualitative - Build a model which will indicate if the loan would ever be delinquent, the delinquency could be of 30, 60, 90 or 120 days.  
  2. Quantitative - Build a model which will provide the interest rate when the person applies for the loan. 
  3. Unsupervised - Identify correlation between various credit decisioning variables like fico, dti, annual income etc using PCA and K-Mean. 
  
  
  Please note that some of the research objective have changed than what were quoted in the project out line document in Week-5,  
    a. Instead of loan amount, now predicting interest rate. 
    b. For qualitative predicting only delinquency and not charge offs. 
  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(MASS)
library(boot)
library(glmnet)
library(leaps)
library(pls)
library(sqldf)
library(data.table)
library(ggplot2) 
library(readr) 
library(gridExtra)
library(tidyverse)
library(sf)
library(maps)
library(caret)
library(class)
library(tree)
library(gbm)
library(randomForest)
library(ggfortify)
library(factoextra)
set.seed(123456)
```


# Feature engineering 

Load the whole dataset 
```{r, read_full_dateset}
lendingClubLoanData <- fread("data/Lending_club_dataset.csv", header = TRUE)
```

Create a origination year fild on the dataset, so that all loans which have originated in 2018 can be extracted. 
```{r, adjust_issue_date}
nrow(lendingClubLoanData)
lendingClubLoanData$orig_year<-substr(lendingClubLoanData$issue_d,5,8)
```

```{r, filter_2018_data}
lendingClubLoanData_2018 <- lendingClubLoanData %>%
  filter(orig_year == 2018)
```


```{r, 2018_number_rows}
lc_ds_size <- nrow(lendingClubLoanData_2018)
lc_ds_size
```

Dataset which will used for this analysis would comprise of `r lc_ds_size` observations.

Create file for all loans which originated in 2018
```{r, write_2018_file}
nrow(lendingClubLoanData_2018)
write.csv(lendingClubLoanData_2018, file = "data/lending_club_loan_data_2018_final.csv", row.names=FALSE)
```

Load the final data set for analysis
```{r final_dateset}
final_dataset <- fread("data/lending_club_loan_data_2018_final.csv", header = TRUE)
drops <- c("id","member_id", "url", "desc")
#final_dataset[ , !(names(final_dataset) %in% drops)]
```


List down all varibales in the dataset
```{r, final_dateset_names}
names(final_dataset)
```
Summary of all the varibales in the dataset
```{r, summary_all_attributes}
summary(final_dataset)
```


## Variable Selection
  1. Dataset contains lot of variables, some of these varibales are associated with secondary applicant,  so excluding those variables. Some other varibales contian
  lot of NA values so dropped those variables 

```{r final_datset_attrib_filtering}
ds_lc <- final_dataset[,c("loan_amnt",
  "funded_amnt",
  "funded_amnt_inv",
  "term",
  "int_rate",
  "installment",
  "grade",
  "sub_grade",
  "home_ownership",
  "annual_inc",
  "loan_status",
  "dti",
  "delinq_2yrs",
  "fico_range_low",
  "fico_range_high",
  "inq_last_6mths",
  "mths_since_last_delinq",
  "mths_since_last_record",
  "open_acc",
  "pub_rec",
  "revol_bal",
  "revol_util",
  "total_acc",
  "out_prncp",
  "out_prncp_inv",
  "total_pymnt",
  "total_pymnt_inv",
  "total_rec_prncp",
  "total_rec_int",
  "total_rec_late_fee",
  "recoveries",
  "collection_recovery_fee",
  "last_fico_range_high",
  "last_fico_range_low",
  "mths_since_last_major_derog",
  "acc_now_delinq",
  "avg_cur_bal",
  "inq_last_12m", "num_tl_30dpd", "num_tl_90g_dpd_24m", "tot_hi_cred_lim", "num_rev_accts"
  )]
```

## Clean up the datset 
  1. convert all categorical variables to factors
  2. Remove the NA values
  3. Convert variables to numeric or integer
  4. Create a delinquent account flag, loan account becomes deliquent when loan status turns to either of the following (is_acct_delinquent = 1)
    a. Late (16-30 days)
    b. Late (31-120 days)
    c. Charged Off
    d. Default
    e. In Grace Period
    
    Loan status with following is one which is not delinquent (is_acct_delinquent = 0)
    a. Current
    b. Fully Paid
    
```{r, clean_up_dataset}
nrow(ds_lc)
ds_lc <- na.omit(ds_lc, cols = c("dti", "int_rate"))
nrow(ds_lc)
levels(factor(ds_lc$loan_status))
levels(factor(ds_lc$grade))
levels(factor(ds_lc$sub_grade))
levels(factor(ds_lc$home_ownership))
ds_lc$term <- as.integer(as.factor(ds_lc$term)) 
ds_lc$grade <- as.integer(as.factor(ds_lc$grade))
ds_lc$sub_grade <- as.integer(as.factor(ds_lc$sub_grade))
ds_lc$home_ownership <- as.integer(as.factor(ds_lc$home_ownership))
ds_lc$int_rate <- as.numeric(ds_lc$int_rate)
ds_lc$loan_status <- as.integer(as.factor(ds_lc$loan_status))
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 1] <- 1
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 2] <- 0
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 3] <- 1
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 4] <- 0
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 5] <- 1
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 6] <- 0
#ds_lc$is_acct_delinquent[ds_lc$loan_status == 7] <- 1
#ds_lc$is_acct_delinquent <- factor(ds_lc$is_acct_delinquent)
#levels(factor(ds_lc$is_acct_delinquent))
#ds_lc = subset(ds_lc, select = -c(loan_status))
```

```{r dataset_correlation_matrix}
cor(ds_lc)
```

Based on the above correlation matrix, following variables are highly collinear 
  1. loan_amnt, funded_amnt, funded_amnt_inv
  2. int_rate, grade, sub_grade
  3. fico_range_low, fico_range_high
  4. last_fico_range_high, last_fico_range_low
  5. total_pymnt, total_pymnt_inv, total_rec_prncp
  
Dropping following varibales due to NA values 
mths_since_last_delinq, mths_since_last_record, mths_since_last_major_derog, avg_cur_bal
  
```{r drop_variables_on_correlation}
ds_lc = subset(ds_lc, select = -c(funded_amnt, funded_amnt_inv, grade, sub_grade, fico_range_low, last_fico_range_low, total_pymnt_inv, total_rec_prncp, mths_since_last_delinq, mths_since_last_record, mths_since_last_major_derog, avg_cur_bal, revol_util))
```

```{r create_loan_delinquent_variable}
ds_lc$is_acct_delinquent[ds_lc$loan_status == 1] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 2] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 3] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 4] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 5] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 6] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 7] <- 1
ds_lc$is_acct_delinquent <- factor(ds_lc$is_acct_delinquent)
levels(factor(ds_lc$is_acct_delinquent))
ds_lc = subset(ds_lc, select = -c(loan_status))
```

Perform regular subset varibale selection test
```{r regular_subset}
regular_subset_full <- regsubsets(is_acct_delinquent ~ ., ds_lc, nvmax = 40)
regular_subset_full_summary <- summary(regular_subset_full)
regular_subset_full_summary
regular_subset_full_summary$rsq
```

```{r regular_subset_plots}
par(mfrow =c(2,2))
plot(regular_subset_full_summary$rss ,xlab=" Number of Variables", ylab=" RSS", type="l")
plot(regular_subset_full_summary$adjr2 ,xlab =" Number of Variables", ylab=" Adjusted RSq",type="l")
points (which.max(regular_subset_full_summary$adjr2), regular_subset_full_summary$adjr2[which.max(regular_subset_full_summary$adjr2)], col ="red",cex =2, pch =20)
plot(regular_subset_full_summary$cp ,xlab =" Number of Variables ",ylab="Cp", type="l")
points (which.min (regular_subset_full_summary$cp ), regular_subset_full_summary$cp [which.min (regular_subset_full_summary$cp )], col ="red",cex =2, pch =20)
plot(regular_subset_full_summary$bic ,xlab=" Number of Variables ",ylab="BIC", type="l")
points(which.min (regular_subset_full_summary$bic), regular_subset_full_summary$bic[which.min(regular_subset_full_summary$bic )], col ="red",cex =2, pch =20)
```

Forward and backward subset selection test.
```{r regular_forward_backward_subset}
forward_subset_full <- regsubsets(is_acct_delinquent ~ ., ds_lc, nvmax = 40, method="forward")
summary(forward_subset_full)
backward_subset_full <- regsubsets(is_acct_delinquent ~ ., ds_lc, nvmax = 40, method="backward")
summary(backward_subset_full)
```

```{r, drop_varibales_based_on_subset}
ds_lc = subset(ds_lc, select = -c(out_prncp_inv,num_tl_30dpd,num_tl_90g_dpd_24m,num_rev_accts,acc_now_delinq,  recoveries, collection_recovery_fee))
```

Check data types for all variables is int or numeric
```{r, check_data_type}
str(ds_lc)
```

Summary for all variables in the dataset along with NA check.
```{r, summary }
summary(ds_lc)
```

Peak at initial set of records.
```{r}
head(ds_lc)
```


## Validation set
Identify whats right the subset distribution for training and test dataset

```{r validation_set_error_1, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.7)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate1 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate1
```

```{r validation_set_error_2, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.75)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim,   
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate2 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate2
```


```{r validation_set_error_3, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.8)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate3 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate3
```


Following is the data split in training and test data ration along with validation error rate/misclassification 
  
    1. Tranining : Test -> 70 : 30, validation error rate `r validation_error_rate1`. or `r validation_error_rate1 * 100`%  
    2. Tranining : Test -> 75 : 25, validation error rate `r validation_error_rate2`. or `r validation_error_rate2 * 100`%  
    3. Tranining : Test -> 80 : 20, validation error rate `r validation_error_rate3`. or `r validation_error_rate3 * 100`%  
    
    
  Validation error rate is different for different sample splits of taining and test dataset. This indicates that validation error rate varies by which 
  observations are in the training/validation sets.


Partition the dataset based on results of above validation set approach.
```{r partition_dataset, message=FALSE}
data_partition <- createDataPartition(y = ds_lc$is_acct_delinquent, p = 0.75, list = FALSE)
train_dataset <- ds_lc[data_partition,]
test_dataset <- ds_lc[-data_partition,]
```

Number of observations in trianing and test dataset
```{r number_rows_train_test}
nrow(train_dataset)
nrow(test_dataset)
```


## Logistic Regression
```{r logistic_regression, message=FALSE}
logistic_regression <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim    
                          ,data = train_dataset, family = binomial)
predictions <- predict(logistic_regression, test_dataset, type="response")
predicted_direction <- ifelse(predictions > 0.5, 1, 0)
error_rate_lr <- mean(predicted_direction != test_dataset$is_acct_delinquent)
error_rate_lr
```

```{r summary_logistic_regression, message=FALSE}
summary(logistic_regression)
```

  Following varibales are statitically significant 
    1. loan_amnt , term, int_rate, installment, annual_inc, fico_range_high, open_acc, pub_rec, total_acc, out_prncp, total_pymnt, total_rec_int, total_rec_late_fee,
    last_fico_range_high.
    2. Following are less significant delinq_2yrs, home_ownership, revol_bal, inq_last_6mths
  

## LDA - Linear Discriminant analysis
```{r lda, message=FALSE}
lda_model <- lda(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim
                          ,data = train_dataset)
predictions <- predict(lda_model, test_dataset, type="response")
confusion_matrix <- table(predictions$class, 
                            test_dataset$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_lda <- mean(predictions$class != test_dataset$is_acct_delinquent)
error_rate_lda
```
```{r}
lda_model
```

## QDA - Quadratic Discriminant Analysis
```{r 10f_qda_1, message=FALSE}
qda_model <- qda(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim
                          ,data = train_dataset)
predictions <- predict(qda_model, test_dataset, type="response")
confusion_matrix <- table(predictions$class, 
                            test_dataset$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_qda <- mean(predictions$class != test_dataset$is_acct_delinquent)
error_rate_qda
```

```{r qda_coefficients}
qda_model
```


## KNN
```{r 10g_knn_1_1, message=FALSE}
train_dataset_matrix <- as.matrix(head(train_dataset, 80000))
test_dataset_matrix <- as.matrix(head(test_dataset, 80000))
train_dataset_mini <- head(train_dataset, 80000)
predictions <- knn(train_dataset_matrix, test_dataset_matrix, train_dataset_mini$is_acct_delinquent, 10)
confusion_matrix <- table(predictions, 
                            train_dataset_mini$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_knn <- mean(predictions != train_dataset_mini$is_acct_delinquent)
error_rate_knn
```

## Tree
```{r tree}
tree_lc <- tree(is_acct_delinquent ~ .,train_dataset)
summary(tree_lc)
tree_lc
plot(tree_lc)
text(tree_lc, pretty=0)
prediction <- predict(tree_lc, test_dataset, type="class")
error_rate_tree <- mean(prediction != test_dataset$is_acct_delinquent)
error_rate_tree
```

  The prime indicator/factor  for is loan account delinquent is last_fico_range_high, out_prncp  and total_rec_late_fee 
  When last_fico_range_high  < 621.5 out_prncp < 158.355 , then probablity of loan account becoming delinquent is high.
  
  
```{r determine_optimal_tree_size}
optimal_tree <- cv.tree(tree_lc, FUN = prune.tree)
optimal_tree
```
  Optimal tree size is 4.

```{r plot_treee_size_error_rate}
tree_plot <- data.frame(x=optimal_tree$size, y=optimal_tree$dev)
ggplot(tree_plot, aes(x=x,y=y)) + 
  geom_point() + 
  geom_line() + 
  xlab("Tree Size") + 
  ylab("Deviance") +
  theme_minimal()
```
```{r pruned_tree_optimal_tree_size}
pruned_tree <- prune.tree(tree_lc, best = 5)
optimal_tree
#optimal_tree <- cv.tree(tree_lc, FUN = prune.tree)
#optimal_tree
```

```{r summary_prunned_tree}
summary(pruned_tree)
summary(tree_lc)
```

```{r pruned_test_error_rate}
test_error_rate_pruned <- mean(predict(pruned_tree, test_dataset, type = "class") != test_dataset$is_acct_delinquent)
test_error_rate_pruned
```
```{r 9k_2_unpruned_test_error_rate}
test_error_rate_unpruned <- mean(prediction != test_dataset$is_acct_delinquent)
test_error_rate_unpruned
```

Test error rate of pruned tree is `r test_error_rate_pruned` and unpruned tree is `r test_error_rate_unpruned`. 


  Tree error rate is `r test_error_rate_pruned`.
  Logistic regression error rate is `r error_rate_lr`.
  LDA error rate is `r error_rate_lda`.
  QDA error rate is `r error_rate_qda`.
  KNN error rate is `r error_rate_knn`.
