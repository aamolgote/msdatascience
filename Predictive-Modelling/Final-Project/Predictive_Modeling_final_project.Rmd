---
title: "Final Project"
author: "Amol Gote"
date: "08/09/2020"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

# Dataset Info
  1. For this project will be using the lending loan club dataset, located at https://www.kaggle.com/wordsforthewise/lending-club
  2. Since this datasize is huge and due to comouting constraints, will using the data for 2018 only. Only approved loans dataset will be in scope for this project. 
  3. Effective dataset size if of 495,242 observations/loans 

# About lending club
  The Lending Club is a peer-to-peer lending service (it lends money to customers by matching lenders to borrowers), based in the United States. This company enables
  borrowers to create loan listings on its website by supplying details about themselves and the loans that they would like to request.

# Dataset Attributes 
  1. Dataset contains various attributes based on which the credit lending decision takes place, this includes Debt to income ratio, annual income, home ownership type
  (Rented,Mortgage, Owned), employment details.  Dataset also contains geographical information like state and zip code. It also has issued loan details like funded Loan
  Amount, issued month and year, loan Term (36 or 60 months) and interest rate. Post loan has been issued, loan performance needs to be tracked, and this dataset
  also contains those details loan Status (Current, Paid Off, Charged Off, Delinquent), loan Grades and delinquency details. 

# Research Objectives
  1. Qualitative - Build a model which will indicate if the loan would ever be delinquent, the delinquency could be of 30, 60, 90 or 120 days.  
  2. Quantitative - Build a model which will provide the interest rate when the person applies for the loan. 
  3. Unsupervised - Identify correlation between various credit decisioning variables like fico, dti, annual income etc using PCA and K-Mean. 
  
  
  Please note that some of the research objective have changed than what were quoted in the project out line document in Week-5,  
    a. Instead of loan amount, now predicting interest rate. 
    b. For qualitative predicting only delinquency and not charge offs. 
  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(MASS)
library(boot)
library(glmnet)
library(leaps)
library(pls)
library(sqldf)
library(data.table)
library(ggplot2) 
library(readr) 
library(gridExtra)
library(tidyverse)
library(sf)
library(maps)
library(caret)
library(class)
library(tree)
library(gbm)
library(randomForest)
library(ggfortify)
library(factoextra)
set.seed(123456)
```


# Feature engineering 

Load the whole dataset 
```{r, read_full_dateset}
lendingClubLoanData <- fread("data/Lending_club_dataset.csv", header = TRUE)
```

Create a origination year fild on the dataset, so that all loans which have originated in 2018 can be extracted. 
```{r, adjust_issue_date}
nrow(lendingClubLoanData)
lendingClubLoanData$orig_year<-substr(lendingClubLoanData$issue_d,5,8)
```

```{r, filter_2018_data}
lendingClubLoanData_2018 <- lendingClubLoanData %>%
  filter(orig_year == 2018)
```


```{r, 2018_number_rows}
lc_ds_size <- nrow(lendingClubLoanData_2018)
lc_ds_size
```

Dataset which will used for this analysis would comprise of `r lc_ds_size` observations.

Create file for all loans which originated in 2018
```{r, write_2018_file}
nrow(lendingClubLoanData_2018)
write.csv(lendingClubLoanData_2018, file = "data/lending_club_loan_data_2018_final.csv", row.names=FALSE)
```

Load the final data set for analysis
```{r final_dateset}
final_dataset <- fread("data/lending_club_loan_data_2018_final.csv", header = TRUE)
drops <- c("id","member_id", "url", "desc")
#final_dataset[ , !(names(final_dataset) %in% drops)]
```


List down all varibales in the dataset
```{r, final_dateset_names}
names(final_dataset)
```
Summary of all the varibales in the dataset
```{r, summary_all_attributes}
summary(final_dataset)
```


## Variable Selection
  1. Dataset contains lot of variables, these variables are attributes associated with existing loans and what we are trying to predict is when loan gets originated,
  at that point in time identify in its life time whether loan would get delinquent at any point in time. So selecting attributes which are available only when loan gets
  onboarded. Most of these attributes come from customers credit bureau report.

```{r final_datset_attrib_filtering}
ds_lc <- final_dataset[,c("loan_amnt",
  "funded_amnt",
  "funded_amnt_inv",
  "term",
  "int_rate",
  "installment",
  "grade",
  "sub_grade",
  "home_ownership",
  "annual_inc",
  "loan_status",
  "dti",
  "delinq_2yrs",
  "fico_range_low",
  "fico_range_high",
  "inq_last_6mths",
  "mths_since_last_delinq",
  "mths_since_last_record",
  "open_acc",
  "pub_rec",
  "revol_bal",
  "revol_util",
  "total_acc",
  "out_prncp",
  "out_prncp_inv",
  "total_pymnt",
  "total_pymnt_inv",
  "total_rec_prncp",
  "total_rec_int",
  "total_rec_late_fee",
  "recoveries",
  "collection_recovery_fee",
  "last_fico_range_high",
  "last_fico_range_low",
  "mths_since_last_major_derog",
  "acc_now_delinq",
  "avg_cur_bal",
  "inq_last_12m", "num_tl_30dpd", "num_tl_90g_dpd_24m", "tot_hi_cred_lim", "num_rev_accts"
  )]
```

## Clean up the datset 
  1. convert all categorical variables to factors
  2. Remove the NA values
  3. Convert variables to numeric or integer
  4. Create a delinquent account flag, loan account becomes deliquent when loan status turns to either of the following (is_acct_delinquent = 1)
    a. Late (16-30 days)
    b. Late (31-120 days)
    c. Charged Off
    d. Default
    e. In Grace Period
    
    Loan status with following is one which is not delinquent (is_acct_delinquent = 0)
    a. Current
    b. Fully Paid
    
```{r, clean_up_dataset}
nrow(ds_lc)
ds_lc <- na.omit(ds_lc, cols = c("dti", "int_rate"))
nrow(ds_lc)
levels(factor(ds_lc$loan_status))
levels(factor(ds_lc$grade))
levels(factor(ds_lc$sub_grade))
levels(factor(ds_lc$home_ownership))
ds_lc$term <- as.integer(as.factor(ds_lc$term)) 
ds_lc$grade <- as.integer(as.factor(ds_lc$grade))
ds_lc$sub_grade <- as.integer(as.factor(ds_lc$sub_grade))
ds_lc$home_ownership <- as.integer(as.factor(ds_lc$home_ownership))
ds_lc$int_rate <- as.numeric(ds_lc$int_rate)
ds_lc$loan_status <- as.integer(as.factor(ds_lc$loan_status))
ds_lc$is_acct_delinquent[ds_lc$loan_status == 1] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 2] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 3] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 4] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 5] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 6] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 7] <- 1
ds_lc$is_acct_delinquent <- factor(ds_lc$is_acct_delinquent)
levels(factor(ds_lc$is_acct_delinquent))
ds_lc = subset(ds_lc, select = -c(loan_status))
```

Perform regular subset varibale selection test
```{r regular_subset}
regular_subset_full <- regsubsets(is_acct_delinquent∼.,ds_lc, nvmax = 25)
regular_subset_full_summary <- summary(regular_subset_full)
regular_subset_full_summary
regular_subset_full_summary$rsq
par(mfrow =c(2,2))
plot(regular_subset_full_summary$rss ,xlab=" Number of Variables", ylab=" RSS", type="l")
plot(regular_subset_full_summary$adjr2 ,xlab =" Number of Variables", ylab=" Adjusted RSq",type="l")
points (which.max(regular_subset_full_summary$adjr2), regular_subset_full_summary$adjr2[which.max(regular_subset_full_summary$adjr2)], col ="red",cex =2, pch =20)
plot(regular_subset_full_summary$cp ,xlab =" Number of Variables ",ylab="Cp", type="l")
points (which.min (regular_subset_full_summary$cp ), regular_subset_full_summary$cp [which.min (regular_subset_full_summary$cp )], col ="red",cex =2, pch =20)
plot(regular_subset_full_summary$bic ,xlab=" Number of Variables ",ylab="BIC", type="l")
points(which.min (regular_subset_full_summary$bic), regular_subset_full_summary$bic[which.min(regular_subset_full_summary$bic )], col ="red",cex =2, pch =20)
```

Forward and backward subset selection test.
```{r regular_forward_backward_subset}
forward_subset_full <- regsubsets(is_acct_delinquent∼., ds_lc, nvmax = 25, method="forward")
summary(forward_subset_full)
backward_subset_full <- regsubsets(is_acct_delinquent∼., ds_lc, nvmax = 25, method="backward")
summary(backward_subset_full)
```

Based on the above subset selection test, identified following set of final variables.
```{r, dataset_with_final_variables}
ds_lc <- ds_lc[,c(
  "loan_amnt",
  "term",
  "int_rate",
  "installment",
  "grade",
  "sub_grade",
  "home_ownership",
  "annual_inc",
  "is_acct_delinquent",
  "dti",
  "delinq_2yrs",
  "fico_range_low",
  "fico_range_high",
  "inq_last_6mths",
  "open_acc",
  "pub_rec",
  "total_acc",
  "last_fico_range_high", 
  "last_fico_range_low", 
  "inq_last_12m",    
  "num_tl_30dpd",      
  "num_tl_90g_dpd_24m", 
  "tot_hi_cred_lim",   
  "num_rev_accts"    
  )]
```

Check data types for all variables is int or numeric
```{r, check_data_type}
str(ds_lc)
```

Summary for all variables in the dataset along with NA check.
```{r, summary }
summary(ds_lc)
```


```{r, correlation_plot_1}
corr_ds_subset <- sample(nrow(ds_lc), 1000)
corr_ds <- ds_lc[corr_ds_subset, ]
pairs(~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership
      , corr_ds)
```
```{r, correlation_plot_2}
pairs(~ 
    annual_inc + 
    delinq_2yrs +
    fico_range_low +
    fico_range_high +
    inq_last_6mths +
    open_acc +
    pub_rec
    ,corr_ds)
```
```{r, correlation_plot_3}
pairs(~ 
    total_acc +
    last_fico_range_high +
    last_fico_range_low +
    inq_last_12m +
    num_tl_30dpd +      
    num_tl_90g_dpd_24m +
    tot_hi_cred_lim +
    num_rev_accts 
    ,corr_ds)
```
Peak at initial set of records.
```{r}
head(ds_lc)
```


## Validation set
Identify whats right the subset distribution for training and test dataset

```{r validation_set_error_2, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.7)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership + 
                          annual_inc + 
                          dti + 
                          delinq_2yrs + 
                          fico_range_low + 
                          fico_range_high + 
                          inq_last_6mths + 
                          open_acc + 
                          pub_rec,
                          total_acc +
                          last_fico_range_high +
                          last_fico_range_low +
                          inq_last_12m +
                          num_tl_30dpd +     
                          num_tl_90g_dpd_24m +
                          tot_hi_cred_lim + 
                          num_rev_accts,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate2 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate2
```

```{r validation_set_error_3, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.75)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership + 
                          annual_inc + 
                          dti + 
                          delinq_2yrs + 
                          fico_range_low + 
                          fico_range_high + 
                          inq_last_6mths + 
                          open_acc + 
                          pub_rec,
                          total_acc +
                          last_fico_range_high +
                          last_fico_range_low +
                          inq_last_12m +
                          num_tl_30dpd +     
                          num_tl_90g_dpd_24m +
                          tot_hi_cred_lim + 
                          num_rev_accts,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate3 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate3
```



```{r validation_set_error_4, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.8)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership + 
                          annual_inc + 
                          dti + 
                          delinq_2yrs + 
                          fico_range_low + 
                          fico_range_high + 
                          inq_last_6mths + 
                          open_acc + 
                          pub_rec,
                          total_acc +
                          last_fico_range_high +
                          last_fico_range_low +
                          inq_last_12m +
                          num_tl_30dpd +     
                          num_tl_90g_dpd_24m +
                          tot_hi_cred_lim + 
                          num_rev_accts,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate4 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate4
```

Following is the data split in training and test data ration along with validation error rate/misclassification 
  
    1. Tranining : Test -> 70 : 30, validation error rate `r validation_error_rate2`. or `r validation_error_rate2 * 100`%  
    2. Tranining : Test -> 75 : 25, validation error rate `r validation_error_rate3`. or `r validation_error_rate3 * 100`%  
    3. Tranining : Test -> 80 : 20, validation error rate `r validation_error_rate3`. or `r validation_error_rate4 * 100`%  
    
    
  Validation error rate is different for different sample splits of taining and test dataset. This indicates that validation error rate varies by which 
  observations are in the training/validation sets.

Partition the dataset based on results of above validation set approach.
```{r partition_dataset, message=FALSE}
data_partition <- createDataPartition(y = ds_lc$is_acct_delinquent, p = 0.75, list = FALSE)
train_dataset <- ds_lc[data_partition,]
test_dataset <- ds_lc[-data_partition,]
```

```{r}
nrow(train_dataset)
nrow(test_dataset)
```

## Logistic Regression
```{r logistic_regression, message=FALSE}
logistic_regression <- glm(is_acct_delinquent ~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership + 
                          annual_inc + 
                          dti + 
                          delinq_2yrs + 
                          fico_range_low + 
                          fico_range_high + 
                          inq_last_6mths + 
                          open_acc + 
                          pub_rec +
                          total_acc +
                          last_fico_range_high +
                          last_fico_range_low +
                          inq_last_12m +
                          num_tl_30dpd +     
                          num_tl_90g_dpd_24m +
                          tot_hi_cred_lim + 
                          num_rev_accts    
                          ,data = train_dataset, family = binomial)

predictions <- predict(logistic_regression, test_dataset, type="response")
predicted_direction <- ifelse(predictions > 0.5, 1, 0)
error_rate_lr <- mean(predicted_direction != test_dataset$is_acct_delinquent)
error_rate_lr
```

## LDA - Linear Discriminant analysis
```{r lda, message=FALSE}
lda_model <- lda(is_acct_delinquent ~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership + 
                          annual_inc + 
                          dti + 
                          delinq_2yrs + 
                          fico_range_low + 
                          fico_range_high + 
                          inq_last_6mths + 
                          open_acc + 
                          pub_rec +
                          total_acc +
                          last_fico_range_high +
                          last_fico_range_low +
                          inq_last_12m +
                          num_tl_30dpd +     
                          num_tl_90g_dpd_24m +
                          tot_hi_cred_lim + 
                          num_rev_accts
                          ,data = train_dataset)
predictions <- predict(lda_model, test_dataset, type="response")
confusion_matrix <- table(predictions$class, 
                            test_dataset$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_lda <- mean(predictions$class != test_dataset$is_acct_delinquent)
error_rate_lda
```

## QDA - Quadratic Discriminant Analysis
```{r 10f_qda_1, message=FALSE}
qda_model <- qda(is_acct_delinquent ~ 
                          loan_amnt + 
                          term + 
                          int_rate + 
                          installment + 
                          grade + 
                          sub_grade + 
                          home_ownership + 
                          annual_inc + 
                          dti + 
                          delinq_2yrs + 
                          fico_range_low + 
                          fico_range_high + 
                          inq_last_6mths + 
                          open_acc + 
                          pub_rec +
                          total_acc +
                          last_fico_range_high +
                          last_fico_range_low +
                          inq_last_12m +
                          num_tl_30dpd +     
                          num_tl_90g_dpd_24m +
                          tot_hi_cred_lim + 
                          num_rev_accts, 
                          data = train_dataset)
predictions <- predict(qda_model, test_dataset, type="response")
confusion_matrix <- table(predictions$class, 
                            test_dataset$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_qda <- mean(predictions$class != test_dataset$is_acct_delinquent)
error_rate_qda
```

## KNN
```{r 10g_knn_1_1, message=FALSE}
train_dataset_matrix <- as.matrix(head(train_dataset, 80000))
test_dataset_matrix <- as.matrix(head(test_dataset, 80000))
train_dataset_mini <- head(train_dataset, 80000)
predictions <- knn(train_dataset_matrix, test_dataset_matrix, train_dataset_mini$is_acct_delinquent, 10)
confusion_matrix <- table(predictions, 
                            train_dataset_mini$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_knn <- mean(predictions != train_dataset_mini$is_acct_delinquent)
error_rate_knn
```

## Tree
```{r tree}
tree_lc <- tree(is_acct_delinquent ~ .,train_dataset)
summary(tree_lc)
tree_lc
plot(tree_lc)
text(tree_lc, pretty=0)
prediction <- predict(tree_lc, test_dataset, type="class")
error_rate_tree <- mean(prediction != test_dataset$is_acct_delinquent)
error_rate_tree
```
 The prime indicator/factor  for is loan account delinquent is last_fico_range_high 
 When high fico reaches below 581, then probablity of loan account becoming delinquent is high.
 

```{r determine_optimal_tree_size}
optimal_tree <- cv.tree(tree_lc, FUN = prune.tree)
optimal_tree
```
  OPtimal tree size is 4.

```{r plot_treee_size_error_rate}
tree_plot <- data.frame(x=optimal_tree$size, y=optimal_tree$dev)
ggplot(tree_plot, aes(x=x,y=y)) + 
  geom_point() + 
  geom_line() + 
  xlab("Tree Size") + 
  ylab("Deviance") +
  theme_minimal()
```
```{r pruned_tree_optimal_tree_size}
pruned_tree <- prune.tree(tree_lc, best = 4)
optimal_tree
#optimal_tree <- cv.tree(tree_lc, FUN = prune.tree)
#optimal_tree
```

```{r summary_prunned_tree}
summary(pruned_tree)
summary(tree_lc)
```

```{r pruned_test_error_rate}
test_error_rate_pruned <- mean(predict(pruned_tree, test_dataset, type = "class") != test_dataset$is_acct_delinquent)
test_error_rate_pruned
```
```{r 9k_2_unpruned_test_error_rate}
test_error_rate_unpruned <- mean(prediction != test_dataset$is_acct_delinquent)
test_error_rate_unpruned
```

  Test error rate of pruned tree is `r test_error_rate_pruned` and unpruned tree is `r test_error_rate_unpruned`. 
  
  Tree error rate is `r test_error_rate_pruned`.
  Logistic regression error rate is `r error_rate_lr`.
  LDA error rate is `r error_rate_lda`.
  QDA error rate is `r error_rate_qda`.
  KNN error rate is `r error_rate_knn`.
  
  All the error rates are almost identical except QDA and KNN, but KNN did not run agains full dataset, so ignoring KNN based models, QDA error rate is bit on higher side,
  so models to predict loan account delinquency would be logistic regression, LDA or Tree
  
  

# Predicting the Interest Rate

## Data Preparation, reset the training and test dataset, identify the interest mean for test dataset
```{r interest_rate_mse}
train_dataset_subset <- sample(nrow(ds_lc) * 0.75)
train_dataset <- ds_lc[train_dataset_subset, ]
test_dataset <- ds_lc[-train_dataset_subset, ]
nrow(train_dataset)
nrow(test_dataset)
test_interest_mean <- mean(test_dataset$int_rate)
test_interest_mse <-  mean((test_dataset$int_rate - test_interest_mean)^2)
test_interest_mean
test_interest_mse
```

## Fit a linear model using least squares on the training set, and identify the test error obtained.
```{r lm_least_Square_interest_rates}
lm_fit <- lm(int_rate ~ . , data = train_dataset)
lm_predictions <- predict(lm_fit, test_dataset)
lm_mse <- mean((lm_predictions - test_dataset$int_rate)^2)
lm_mse
```

## Fit a ridge regression model and identify the test error obtained.
```{r ridge_regression_model_interest_rates}
train_ds_matrix <- model.matrix(int_rate ~ ., data = train_dataset)
test_ds_matrix <- model.matrix(int_rate ~ ., data = test_dataset)

grid <- 10 ^ seq(4, -2, length = 100)

ridge_reg_model <- cv.glmnet(train_ds_matrix, train_dataset$int_rate, alpha = 0, lambda = grid, thresh = 1e-12)
ridge_reg_predictions <- predict(ridge_reg_model, test_ds_matrix, s = ridge_reg_model$lambda.min)
ridge_mse <- mean((test_dataset$int_rate - ridge_reg_predictions)^2)
ridge_mse
```

## Fit a Lasso model and identify the test error obtained.
```{r lasso_model_interest_rates}
lasso_model <- cv.glmnet(train_ds_matrix, train_dataset$int_rate, alpha = 1, lambda = grid, thresh = 1e-12)
lasso_predictions <- predict(lasso_model, test_ds_matrix, s = lasso_model$lambda.min)
lasso_mse <- mean((test_dataset$int_rate - lasso_predictions)^2)
lasso_rmse <- sqrt(mean((test_dataset$int_rate - lasso_predictions)^2))
lasso_mse
```

## Fit a PCR model and identify the test error obtained.
```{r pcr_model_interest_rates}
pcr_model <- pcr(int_rate ~ . , data = train_dataset, scale=T, validation="CV")
validationplot(pcr_model, val.type = "MSEP")
pcr_predictions <- predict(pcr_model, test_dataset, ncomp = 15)
pcr_mse <- mean((test_dataset$int_rate - pcr_predictions)^2)
pcr_rmse <- sqrt(mean((test_dataset$int_rate - pcr_predictions)^2))
pcr_mse
```


## Fit a PLS model and identify the test error obtained.
```{r pls_model_interest_rates}
pls_model <- plsr(int_rate ~ . , data = train_dataset, scale=T, validation="CV")
validationplot(pls_model, val.type = "MSEP")
pls_predictions <- predict(pls_model, test_dataset, ncomp = 15)
pls_mse <- mean((test_dataset$int_rate  - pls_predictions)^2)
pls_rmse <- sqrt(mean((test_dataset$int_rate  - pls_predictions)^2))
pls_mse
```

Compare R2 values for various models
```{r model_comparison}
lm_test_r2 <- (1 - (lm_mse/test_interest_mse))
ridge_test_r2 <- (1 - (ridge_mse/test_interest_mse))
lasso_test_r2 <- (1 - (lasso_mse/test_interest_mse))
pcr_test_r2 <- (1 - (pcr_mse/test_interest_mse))
pls_test_r2 <- (1 - (pls_mse/test_interest_mse))

cat("R square with linear model : ", lm_test_r2, "\n")
cat("R square with ridge model :  ", ridge_test_r2, "\n")
cat("R square with lasso model :  ", lasso_test_r2, "\n")
cat("R square with pcr :          ", pcr_test_r2, "\n")
cat("R square with pls :          ", pls_test_r2, "\n")

barplot(c(lm_test_r2, ridge_test_r2, lasso_test_r2, pcr_test_r2, pls_test_r2),
        names.arg = c("LM", "Ridge", "Lasso", "PCR", "PLS"))

```

  All models have R Square values near to 0.9. All models predict interest rate with high accuracy, pcr has lesser accuracy than others.

## Boosting 
  Changed the dataset size due to systme constraints
```{r, boosting}
train_dataset_mini <- train_dataset[1:1000,]
test_dataset_mini <- test_dataset[(1:1000),]

pows <- seq(-10, -0.2, by = 0.1)
lambdas <- 10^pows
training_errors <- rep(NA, length(lambdas))


for (i in 1:length(lambdas)) {
  boosting_model <- gbm(int_rate ~ . , data = train_dataset_mini, distribution = "gaussian", 
                       n.trees = 1000, shrinkage = lambdas[i])
  
  training_predictions <- predict(boosting_model, train_dataset_mini, n.trees = 1000)
  training_errors[i] <- mean((training_predictions - train_dataset_mini$int_rate)^2)
}

plot(lambdas, training_errors, xlab = "Shrinkage Values", ylab = "Training set MSE", type = "b", pch = 20)
```


```{r, boosting_plot, message=FALSE}
test_errors <- rep(NA, length(lambdas))


for (i in 1:length(lambdas)) {
  boosting_model <- gbm(int_rate ~ . , data = train_dataset_mini, distribution = "gaussian", 
                       n.trees = 1000, shrinkage = lambdas[i])
  
  test_predictions <- predict(boosting_model, test_dataset_mini, n.trees = 1000)
  test_errors[i] <- mean((test_predictions - test_dataset_mini$int_rate)^2)
}

plot(lambdas, test_errors, xlab = "Shrinkage Values", ylab = "Training set MSE", type = "b", pch = 20)
min(test_errors)
min_test_err <- min(test_errors)
min_test_err_at <- lambdas[which.min(test_errors)]
```

Both regression approaches lm and lasso have higher MSE compared to that of boosting.


```{r, important_varaible_predictor_boosting}
boosting_model <- gbm(int_rate ~ . , data = train_dataset_mini, distribution = "gaussian", 
                       n.trees = 1000, shrinkage = min_test_err)
summary(boosting_model)
```

 Variables that appear to be most important predictors are 
  1. sub_grade
  2. grade
  3. open_acc
  4. num_rev_Accts
  5. annual_inc

## Bagging
```{r, 10g_apply_bagging}
random_forest_model <- randomForest(int_rate ~ . , data = train_dataset_mini, ntree = 500, mtry = ncol(train_dataset_mini)-1)
random_forest_predictions <- predict(random_forest_model, test_dataset_mini)

random_forest_test_mse <- mean((random_forest_predictions - test_dataset_mini$int_rate)^2)
random_forest_test_mse
```

Test MSE for bagging is `r random_forest_test_mse` which is better than `r min_test_err` which is best MSE from boosting

# Unspervised Learning - PCA
```{r, unspervised_learning_pca}
ds_lc_pca <- ds_lc[,c(
  "loan_amnt",
  "term",
  "int_rate",
  "installment",
  "grade",
  "sub_grade",
  "home_ownership",
  "annual_inc",
  "dti",
  "delinq_2yrs",
  "fico_range_low",
  "fico_range_high",
  "inq_last_6mths",
  "open_acc",
  "pub_rec",
  "total_acc",
  "last_fico_range_high", 
  "last_fico_range_low", 
  "inq_last_12m",    
  "tot_hi_cred_lim",   
  "num_rev_accts"    
  )]
ds_lc_pca_subset <- sample(nrow(ds_lc), 1000)
ds_lc_pca = ds_lc_pca[ds_lc_pca_subset, ]

str(ds_lc_pca)
pr.out <- prcomp (ds_lc_pca, scale =TRUE)
names(pr.out)
pr.out$center
pr.out$scale
pr.out$rotation
biplot(pr.out)
```

```{r,  unspervised_learning_pca_plot}
pr.out$rotation=-pr.out$rotation
pr.out$x=-pr.out$x
biplot (pr.out , scale =0)
#pr.out$sdev
pr.var =pr.out$sdev ^2
pve=pr.var/sum(pr.var )
pve
plot(pve , xlab="Principal Component ", ylab="Proportion of Variance Explained ", ylim=c(0,1) ,type="b")
plot(cumsum (pve ), xlab="Principal Component ", ylab ="Cumulative Proportion of Variance Explained ", ylim=c(0,1) , type="b")
```

```{r,  unspervised_learning_pca_bar_chart}
#autoplot(pr.out)
biplot (pr.out , scale =0)
fviz_eig(pr.out, addlabels = TRUE, ylim = c(0, 50))
```

PCA does not bring in much value. Very dimension were identified with PCA.

```{r,  unspervised_learning_kmean}
ds_lc_kmean <- ds_lc[,c(
  "loan_amnt",
  "term",
  "int_rate",
  "installment",
  "grade",
  "sub_grade",
  "home_ownership",
  "annual_inc",
  "dti",
  "delinq_2yrs",
  "fico_range_low",
  "fico_range_high",
  "inq_last_6mths",
  "open_acc",
  "pub_rec",
  "total_acc",
  "last_fico_range_high", 
  "last_fico_range_low", 
  "inq_last_12m",    
  "tot_hi_cred_lim",   
  "num_rev_accts"    
  )]
ds_lc_kmean_subset <- sample(nrow(ds_lc_kmean), 1000)
ds_lc_kmean = ds_lc_kmean[ds_lc_kmean_subset, ]
ds_lc_kmean_scaled <- as.data.frame(scale(ds_lc_kmean))
```

```{r, unspervised_learning_kmean_cluster_size}
k2 <- kmeans(ds_lc_kmean_scaled, centers = 2, nstart = 25)
k3 <- kmeans(ds_lc_kmean_scaled, centers = 3, nstart = 25)
k4 <- kmeans(ds_lc_kmean_scaled, centers = 4, nstart = 25)
k5 <- kmeans(ds_lc_kmean_scaled, centers = 5, nstart = 25)
k6 <- kmeans(ds_lc_kmean_scaled, centers = 6, nstart = 25)
k7 <- kmeans(ds_lc_kmean_scaled, centers = 7, nstart = 25)
k8 <- kmeans(ds_lc_kmean_scaled, centers = 8, nstart = 25)
k9 <- kmeans(ds_lc_kmean_scaled, centers = 9, nstart = 25)


# plots to compare
p2 <- fviz_cluster(k2, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 2")
p3 <- fviz_cluster(k3, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 3")
p4 <- fviz_cluster(k4, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 4")
p5 <- fviz_cluster(k5, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 5")
p6 <- fviz_cluster(k6, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 6")
p7 <- fviz_cluster(k7, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 7")
p8 <- fviz_cluster(k8, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 8")
p9 <- fviz_cluster(k9, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 9")
p10 <- fviz_cluster(k9, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 10")


grid.arrange(p2, p3, p4, p5,  nrow = 2)
grid.arrange(p6, p7, p8, p9,  nrow = 2)
grid.arrange(p10,  nrow = 2)
```

```{r unspervised_learning_kmean_elbow, message=FALSE}
set.seed(1234)
#Function to compute total within cluster sum of squares 
wss <- function(k) {
  kmeans(ds_lc_kmean_scaled, k, nstart = 25, iter.max = 10)$tot.withinss
}

#Compute and plot the within sum of squares (wss) for k = 1 to k = 10
k.values <- 1:15

#Extract wss for 2 - 10 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
     type = "b", pch = 19, frame = FALSE,
     xlab = "Number of clusters K",
     ylab = "Total within clusters sum of squares")

set.seed(1234)
fviz_nbclust(ds_lc_kmean_scaled, kmeans, method = "wss")
```

Based on the visualization 3 or 4 clusters seems to be better classification. 3 clusters have very less overlap compared to that of the 4 clusters. 

```{r, unspervised_learning_kmean_asign_cluster}
ds_lc_kmean$cluster <- k4$cluster
```

```{r assignCustomerCategories}
ds_lc_kmean$category <- ""
for(i in 1:nrow(ds_lc_kmean)){
    if (ds_lc_kmean$cluster[i] == 1){
        ds_lc_kmean$category[i] <- "Low"
    }
    else if (ds_lc_kmean$cluster[i] == 2){
      ds_lc_kmean$category[i] <- "Low-Medium"
    }
    else if (ds_lc_kmean$cluster[i] == 3){
      ds_lc_kmean$category[i] <- "Medium"
    }
    else if (ds_lc_kmean$cluster[i] == 4){
      ds_lc_kmean$category[i] <- "High"
    }
}

low_risk_loans <- ds_lc_kmean %>%
  filter(category == "Low")

low_medium_risk_loans <- ds_lc_kmean %>%
  filter(category == "Low-Medium")

medium_risk_loans <- ds_lc_kmean %>%
  filter(category == "Medium")

high_risk_loans <- ds_lc_kmean %>%
  filter(category == "High")

```

```{r, unspervised_learning_kmean_interest_rate}
mean(low_risk_loans$int_rate)
mean(low_medium_risk_loans$int_rate)
mean(medium_risk_loans$int_rate)
mean(high_risk_loans$int_rate)
```

```{r, unspervised_learning_kmean_annual_income}
mean(low_risk_loans$annual_inc)
mean(low_medium_risk_loans$annual_inc)
mean(medium_risk_loans$annual_inc)
mean(high_risk_loans$annual_inc)
```

```{r, unspervised_learning_kmean_dti}
mean(low_risk_loans$dti)
mean(low_medium_risk_loans$dti)
mean(medium_risk_loans$dti)
mean(high_risk_loans$dti)
```

```{r, unspervised_learning_kmean_fico_range_low}
mean(low_risk_loans$fico_range_low)
mean(low_medium_risk_loans$fico_range_low)
mean(medium_risk_loans$fico_range_low)
mean(high_risk_loans$fico_range_low)
```

```{r, unspervised_learning_kmean_fico_range_high}
mean(low_risk_loans$fico_range_high)
mean(low_medium_risk_loans$fico_range_high)
mean(medium_risk_loans$fico_range_high)
mean(high_risk_loans$fico_range_high)
```

```{r, unspervised_learning_kmean_inq_last_6mths}
mean(low_risk_loans$inq_last_6mths)
mean(low_medium_risk_loans$inq_last_6mths)
mean(medium_risk_loans$inq_last_6mths)
mean(high_risk_loans$inq_last_6mths)
```
```{r, unspervised_learning_kmean_delinq_2yrs}
mean(low_risk_loans$delinq_2yrs)
mean(low_medium_risk_loans$delinq_2yrs)
mean(medium_risk_loans$delinq_2yrs)
mean(high_risk_loans$delinq_2yrs)
```

```{r, unspervised_learning_kmean_grade}
mean(low_risk_loans$grade)
mean(low_medium_risk_loans$grade)
mean(medium_risk_loans$grade)
mean(high_risk_loans$grade)
```

```{r, unspervised_learning_kmean_sub_grade}
mean(low_risk_loans$sub_grade)
mean(low_medium_risk_loans$sub_grade)
mean(medium_risk_loans$sub_grade)
mean(high_risk_loans$sub_grade)
```
