---
title: "Final Project"
author: "Amol Gote"
date: "08/09/2020"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

# Dataset Info
  1. For this project will be using the lending loan club dataset, located at https://www.kaggle.com/wordsforthewise/lending-club
  2. Since this datasize is huge and due to comouting constraints, will using the data for 2018 only. Only approved loans dataset will be in scope for this project. 
  3. Effective dataset size if of 495,242 observations/loans 

# About lending club
  The Lending Club is a peer-to-peer lending service (it lends money to customers by matching lenders to borrowers), based in the United States. This company enables
  borrowers to create loan listings on its website by supplying details about themselves and the loans that they would like to request.

# Dataset Attributes 
  1. Dataset contains various attributes based on which the credit lending decision takes place, this includes Debt to income ratio, annual income, home ownership type
  (Rented,Mortgage, Owned), employment details.  Dataset also contains geographical information like state and zip code. It also has issued loan details like funded Loan
  Amount, issued month and year, loan Term (36 or 60 months) and interest rate. Post loan has been issued, loan performance needs to be tracked, and this dataset
  also contains those details loan Status (Current, Paid Off, Charged Off, Delinquent), loan Grades and delinquency details. 

# Research Objectives
  1. Qualitative - Build a model which will indicate if the loan would ever be delinquent, the delinquency could be of 30, 60, 90 or 120 days.  
  2. Quantitative - Build a model which will provide the interest rate when the person applies for the loan. 
  3. Unsupervised - Identify correlation between various credit decisioning variables like fico, dti, annual income,  etc using PCA and K-Mean. 
  
  
  Please note that some of the research objective have changed than what were quoted in the project out line document in Week-5,  
    a. Instead of loan amount, now predicting interest rate. 
    b. For qualitative predicting only delinquency and not charge offs. 
  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(MASS)
library(boot)
library(glmnet)
library(leaps)
library(pls)
library(sqldf)
library(data.table)
library(ggplot2) 
library(readr) 
library(gridExtra)
library(tidyverse)
library(sf)
library(maps)
library(caret)
library(class)
library(tree)
library(gbm)
library(randomForest)
library(ggfortify)
library(factoextra)
set.seed(123456)
```


# Feature engineering 

Load the whole dataset 
```{r, read_full_dateset}
lendingClubLoanData <- fread("data/Lending_club_dataset.csv", header = TRUE)
```

Create a origination year fild on the dataset, so that all loans which have originated in 2018 can be extracted. 
```{r, adjust_issue_date}
nrow(lendingClubLoanData)
lendingClubLoanData$orig_year<-substr(lendingClubLoanData$issue_d,5,8)
```

```{r, filter_2018_data}
lendingClubLoanData_2018 <- lendingClubLoanData %>%
  filter(orig_year == 2018)
```


```{r, 2018_number_rows}
lc_ds_size <- nrow(lendingClubLoanData_2018)
lc_ds_size
```

Dataset which will used for this analysis would comprise of `r lc_ds_size` observations.

Create file for all loans which originated in 2018
```{r, write_2018_file}
nrow(lendingClubLoanData_2018)
write.csv(lendingClubLoanData_2018, file = "data/lending_club_loan_data_2018_final.csv", row.names=FALSE)
```

Load the final data set for analysis
```{r final_dateset}
final_dataset <- fread("data/lending_club_loan_data_2018_final.csv", header = TRUE)
drops <- c("id","member_id", "url", "desc")
#final_dataset[ , !(names(final_dataset) %in% drops)]
```


List down all varibales in the dataset
```{r, final_dateset_names}
names(final_dataset)
```
Summary of all the varibales in the dataset
```{r, summary_all_attributes}
summary(final_dataset)
```


## Variable Selection
  1. Dataset contains lot of variables, some of these varibales are associated with secondary applicant,  so excluding those variables. Some other varibales contian
  lot of NA values so dropped those variables 

```{r final_datset_attrib_filtering}
ds_lc <- final_dataset[,c("loan_amnt",
  "funded_amnt",
  "funded_amnt_inv",
  "term",
  "int_rate",
  "installment",
  "grade",
  "sub_grade",
  "home_ownership",
  "annual_inc",
  "loan_status",
  "dti",
  "delinq_2yrs",
  "fico_range_low",
  "fico_range_high",
  "inq_last_6mths",
  "mths_since_last_delinq",
  "mths_since_last_record",
  "open_acc",
  "pub_rec",
  "revol_bal",
  "revol_util",
  "total_acc",
  "out_prncp",
  "out_prncp_inv",
  "total_pymnt",
  "total_pymnt_inv",
  "total_rec_prncp",
  "total_rec_int",
  "total_rec_late_fee",
  "recoveries",
  "collection_recovery_fee",
  "last_fico_range_high",
  "last_fico_range_low",
  "mths_since_last_major_derog",
  "acc_now_delinq",
  "avg_cur_bal",
  "inq_last_12m", "num_tl_30dpd", "num_tl_90g_dpd_24m", "tot_hi_cred_lim", "num_rev_accts"
  )]
```

## Clean up the datset 
  1. convert all categorical variables to factors
  2. Remove the NA values
  3. Convert variables to numeric or integer
  4. Create a delinquent account flag, loan account becomes deliquent when loan status turns to either of the following (is_acct_delinquent = 1)
    a. Late (16-30 days)
    b. Late (31-120 days)
    c. Charged Off
    d. Default
    e. In Grace Period
    
    Loan status with following is one which is not delinquent (is_acct_delinquent = 0)
    a. Current
    b. Fully Paid
    
```{r, clean_up_dataset}
nrow(ds_lc)
ds_lc <- na.omit(ds_lc, cols = c("dti", "int_rate"))
nrow(ds_lc)
levels(factor(ds_lc$loan_status))
levels(factor(ds_lc$grade))
levels(factor(ds_lc$sub_grade))
levels(factor(ds_lc$home_ownership))
ds_lc$term <- as.integer(as.factor(ds_lc$term)) 
ds_lc$grade <- as.integer(as.factor(ds_lc$grade))
ds_lc$sub_grade <- as.integer(as.factor(ds_lc$sub_grade))
ds_lc$home_ownership <- as.integer(as.factor(ds_lc$home_ownership))
ds_lc$int_rate <- as.numeric(ds_lc$int_rate)
ds_lc$loan_status <- as.integer(as.factor(ds_lc$loan_status))
```

```{r dataset_correlation_matrix}
cor(ds_lc)
```

Based on the above correlation matrix, following variables are highly collinear 
  1. loan_amnt, funded_amnt, funded_amnt_inv
  2. int_rate, grade, sub_grade
  3. fico_range_low, fico_range_high
  4. last_fico_range_high, last_fico_range_low
  5. total_pymnt, total_pymnt_inv, total_rec_prncp
  
Dropping following varibales due to NA values 
mths_since_last_delinq, mths_since_last_record, mths_since_last_major_derog, avg_cur_bal
  
```{r drop_variables_on_correlation}
ds_lc = subset(ds_lc, select = -c(funded_amnt, funded_amnt_inv, grade, sub_grade, fico_range_low, last_fico_range_low, total_pymnt_inv, total_rec_prncp, mths_since_last_delinq, mths_since_last_record, mths_since_last_major_derog, avg_cur_bal, revol_util))
```

```{r create_loan_delinquent_variable}
ds_lc$is_acct_delinquent[ds_lc$loan_status == 1] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 2] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 3] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 4] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 5] <- 1
ds_lc$is_acct_delinquent[ds_lc$loan_status == 6] <- 0
ds_lc$is_acct_delinquent[ds_lc$loan_status == 7] <- 1
ds_lc$is_acct_delinquent <- factor(ds_lc$is_acct_delinquent)
levels(factor(ds_lc$is_acct_delinquent))
ds_lc = subset(ds_lc, select = -c(loan_status))
ds_lc_after_correlation <- ds_lc
```

Perform regular subset varibale selection test
```{r regular_subset}
regular_subset_full <- regsubsets(is_acct_delinquent ~ ., ds_lc, nvmax = 40)
regular_subset_full_summary <- summary(regular_subset_full)
regular_subset_full_summary
regular_subset_full_summary$rsq
```

```{r regular_subset_plots}
par(mfrow =c(2,2))
plot(regular_subset_full_summary$rss ,xlab=" Number of Variables", ylab=" RSS", type="l")
plot(regular_subset_full_summary$adjr2 ,xlab =" Number of Variables", ylab=" Adjusted RSq",type="l")
points (which.max(regular_subset_full_summary$adjr2), regular_subset_full_summary$adjr2[which.max(regular_subset_full_summary$adjr2)], col ="red",cex =2, pch =20)
plot(regular_subset_full_summary$cp ,xlab =" Number of Variables ",ylab="Cp", type="l")
points (which.min (regular_subset_full_summary$cp ), regular_subset_full_summary$cp [which.min (regular_subset_full_summary$cp )], col ="red",cex =2, pch =20)
plot(regular_subset_full_summary$bic ,xlab=" Number of Variables ",ylab="BIC", type="l")
points(which.min (regular_subset_full_summary$bic), regular_subset_full_summary$bic[which.min(regular_subset_full_summary$bic )], col ="red",cex =2, pch =20)
```

Forward and backward subset selection test.
```{r regular_forward_backward_subset}
forward_subset_full <- regsubsets(is_acct_delinquent ~ ., ds_lc, nvmax = 40, method="forward")
summary(forward_subset_full)
backward_subset_full <- regsubsets(is_acct_delinquent ~ ., ds_lc, nvmax = 40, method="backward")
summary(backward_subset_full)
```

```{r, drop_varibales_based_on_subset}
ds_lc = subset(ds_lc, select = -c(out_prncp_inv,num_tl_30dpd,num_tl_90g_dpd_24m,num_rev_accts,acc_now_delinq,  recoveries, collection_recovery_fee))
```

Check data types for all variables is int or numeric
```{r, check_data_type}
str(ds_lc)
```

Summary for all variables in the dataset along with NA check.
```{r, summary }
summary(ds_lc)
```

Peak at initial set of records.
```{r}
head(ds_lc)
```


## Validation set
Identify whats right the subset distribution for training and test dataset

```{r validation_set_error_1, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.7)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate1 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate1
```

```{r validation_set_error_2, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.75)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim,   
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate2 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate2
```


```{r validation_set_error_3, message=FALSE}
sample_set<-sample(nrow(ds_lc),nrow(ds_lc)*0.8)
training_dataset <- ds_lc[sample_set,]
test_dataset <- ds_lc[-sample_set,]
regression_model <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim,    
                          data = training_dataset, family = "binomial")
probablity<-predict(regression_model,test_dataset,type="response")
prediction<-ifelse(probablity > 0.5, 1, 0)
validation_error_rate3 <- mean(prediction != test_dataset$is_acct_delinquent)
validation_error_rate3
```


Following is the data split in training and test data ration along with validation error rate/misclassification 
  
    1. Tranining : Test -> 70 : 30, validation error rate `r validation_error_rate1`. or `r validation_error_rate1 * 100`%  
    2. Tranining : Test -> 75 : 25, validation error rate `r validation_error_rate2`. or `r validation_error_rate2 * 100`%  
    3. Tranining : Test -> 80 : 20, validation error rate `r validation_error_rate3`. or `r validation_error_rate3 * 100`%  
    
    
  Validation error rate is different for different sample splits of taining and test dataset. This indicates that validation error rate varies by which 
  observations are in the training/validation sets.


Partition the dataset based on results of above validation set approach.
```{r partition_dataset, message=FALSE}
data_partition <- createDataPartition(y = ds_lc$is_acct_delinquent, p = 0.75, list = FALSE)
train_dataset <- ds_lc[data_partition,]
test_dataset <- ds_lc[-data_partition,]
```

Number of observations in trianing and test dataset
```{r number_rows_train_test}
nrow(train_dataset)
nrow(test_dataset)
```


## Logistic Regression
```{r logistic_regression, message=FALSE}
logistic_regression <- glm(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim    
                          ,data = train_dataset, family = binomial)
predictions <- predict(logistic_regression, test_dataset, type="response")
predicted_direction <- ifelse(predictions > 0.5, 1, 0)
error_rate_lr <- mean(predicted_direction != test_dataset$is_acct_delinquent)
error_rate_lr
```

```{r summary_logistic_regression, message=FALSE}
summary(logistic_regression)
```

  Following variables are statitically significant 
    1. loan_amnt , term, int_rate, installment, annual_inc, fico_range_high, open_acc, pub_rec, total_acc, out_prncp, total_pymnt, total_rec_int, total_rec_late_fee,
    last_fico_range_high.
    2. Following are less significant delinq_2yrs, home_ownership, revol_bal, inq_last_6mths
  

## LDA - Linear Discriminant analysis
```{r lda, message=FALSE}
lda_model <- lda(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          total_pymnt +
                          total_rec_int +
                          total_rec_late_fee +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim
                          ,data = train_dataset)
predictions <- predict(lda_model, test_dataset, type="response")
confusion_matrix <- table(predictions$class, 
                            test_dataset$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_lda <- mean(predictions$class != test_dataset$is_acct_delinquent)
error_rate_lda
```
```{r}
lda_model
```

Based on the coefficient values, all the features are important predictors and significant. 


## QDA - Quadratic Discriminant Analysis
```{r 10f_qda_1, message=FALSE}
qda_model <- qda(is_acct_delinquent ~ 
                          loan_amnt +
                          term +
                          int_rate +
                          installment +
                          home_ownership +
                          annual_inc +
                          dti +
                          delinq_2yrs +
                          fico_range_high +
                          inq_last_6mths +
                          open_acc +
                          pub_rec +
                          revol_bal +
                          total_acc +
                          out_prncp +
                          last_fico_range_high +
                          inq_last_12m +
                          tot_hi_cred_lim
                          ,data = train_dataset)
predictions <- predict(qda_model, test_dataset, type="response")
confusion_matrix <- table(predictions$class, 
                            test_dataset$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_qda <- mean(predictions$class != test_dataset$is_acct_delinquent)
error_rate_qda
```

```{r qda_coefficients}
qda_model
```


## KNN
```{r 10g_knn_1_1, message=FALSE}
train_dataset_matrix <- as.matrix(head(train_dataset, 80000))
test_dataset_matrix <- as.matrix(head(test_dataset, 80000))
train_dataset_mini <- head(train_dataset, 80000)
predictions <- knn(train_dataset_matrix, test_dataset_matrix, train_dataset_mini$is_acct_delinquent, 10)
confusion_matrix <- table(predictions, 
                            train_dataset_mini$is_acct_delinquent, 
                            dnn = c("Predicted Status", "Observed Status"))
confusion_matrix

error_rate_knn <- mean(predictions != train_dataset_mini$is_acct_delinquent)
error_rate_knn
```

## Tree
```{r tree}
tree_lc <- tree(is_acct_delinquent ~ .,train_dataset)
summary(tree_lc)
tree_lc
plot(tree_lc)
text(tree_lc, pretty=0)
prediction <- predict(tree_lc, test_dataset, type="class")
error_rate_tree <- mean(prediction != test_dataset$is_acct_delinquent)
error_rate_tree
```

  The prime indicator/factor  for is loan account delinquent is last_fico_range_high, out_prncp  and total_rec_late_fee 
  When last_fico_range_high  < 621.5 out_prncp < 158.355 , then probablity of loan account becoming delinquent is high.
  
  
```{r determine_optimal_tree_size}
optimal_tree <- cv.tree(tree_lc, FUN = prune.tree)
optimal_tree
```
  Optimal tree size is 4.

```{r plot_treee_size_error_rate}
tree_plot <- data.frame(x=optimal_tree$size, y=optimal_tree$dev)
ggplot(tree_plot, aes(x=x,y=y)) + 
  geom_point() + 
  geom_line() + 
  xlab("Tree Size") + 
  ylab("Deviance") +
  theme_minimal()
```
```{r pruned_tree_optimal_tree_size}
pruned_tree <- prune.tree(tree_lc, best = 5)
optimal_tree
#optimal_tree <- cv.tree(tree_lc, FUN = prune.tree)
#optimal_tree
```

```{r summary_prunned_tree}
summary(pruned_tree)
summary(tree_lc)
```

```{r pruned_test_error_rate}
test_error_rate_pruned <- mean(predict(pruned_tree, test_dataset, type = "class") != test_dataset$is_acct_delinquent)
test_error_rate_pruned
```
```{r 9k_2_unpruned_test_error_rate}
test_error_rate_unpruned <- mean(prediction != test_dataset$is_acct_delinquent)
test_error_rate_unpruned
```

Test error rate of pruned tree is `r test_error_rate_pruned` and unpruned tree is `r test_error_rate_unpruned`. 


  Logistic regression error rate is `r error_rate_lr`.
  LDA error rate is `r error_rate_lda`.
  QDA error rate is `r error_rate_qda`.
  KNN error rate is `r error_rate_knn`.
  Tree error rate is `r test_error_rate_pruned`.
  Unpruned tree error rate is `r test_error_rate_unpruned`.
  
  
# Predicting the Interest Rate

## Data Preparation, reset the training and test dataset, identify the interest mean for test dataset

Perform regular subset varibale selection test
```{r regular_subset_int_rate}
ds_lc <- ds_lc_after_correlation
regular_subset_full <- regsubsets(int_rate ~ ., ds_lc, nvmax = 40)
regular_subset_full_summary <- summary(regular_subset_full)
regular_subset_full_summary
regular_subset_full_summary$rsq
```

```{r, drop_variables_based_on_subset_int_rate}
ds_lc = subset(ds_lc, select = -c(open_acc, revol_bal, total_pymnt, total_rec_late_fee, recoveries, collection_recovery_fee, acc_now_delinq, num_tl_30dpd, total_rec_int, out_prncp, out_prncp_inv, is_acct_delinquent))
```

```{r interest_rate_mse}
train_dataset_subset <- sample(nrow(ds_lc) * 0.75)
train_dataset <- ds_lc[train_dataset_subset, ]
test_dataset <- ds_lc[-train_dataset_subset, ]
nrow(train_dataset)
nrow(test_dataset)
test_interest_mean <- mean(test_dataset$int_rate)
test_interest_mse <-  mean((test_dataset$int_rate - test_interest_mean)^2)
test_interest_mean
test_interest_mse
```
## Fit a linear model using least squares on the training set, and identify the test error obtained.
```{r lm_least_Square_interest_rates}
lm_fit <- lm(int_rate ~ . , data = train_dataset)
lm_predictions <- predict(lm_fit, test_dataset)
lm_mse <- mean((lm_predictions - test_dataset$int_rate)^2)
lm_mse
summary(lm_fit)

```
All the features are important predictors. 

## Fit a ridge regression model and identify the test error obtained.
```{r ridge_regression_model_interest_rates}
train_ds_matrix <- model.matrix(int_rate ~ ., data = train_dataset)
test_ds_matrix <- model.matrix(int_rate ~ ., data = test_dataset)

grid <- 10 ^ seq(4, -2, length = 100)

ridge_reg_model <- cv.glmnet(train_ds_matrix, train_dataset$int_rate, alpha = 0, lambda = grid, thresh = 1e-12)
ridge_reg_predictions <- predict(ridge_reg_model, test_ds_matrix, s = ridge_reg_model$lambda.min)
ridge_mse <- mean((test_dataset$int_rate - ridge_reg_predictions)^2)
ridge_mse
coef(ridge_reg_model)
```
Coefficients of all the variables are significant. All the features are important predictors. 


## Fit a Lasso model and identify the test error obtained.
```{r lasso_model_interest_rates}
lasso_model <- cv.glmnet(train_ds_matrix, train_dataset$int_rate, alpha = 1, lambda = grid, thresh = 1e-12)
lasso_predictions <- predict(lasso_model, test_ds_matrix, s = lasso_model$lambda.min)
lasso_mse <- mean((test_dataset$int_rate - lasso_predictions)^2)
lasso_rmse <- sqrt(mean((test_dataset$int_rate - lasso_predictions)^2))
lasso_mse
coef(lasso_model)
```
Apart for loan_amnt and total_acc all other variable/feature coefficients are statistically significant.


## PCR model
```{r pcr_model_interest_rates}
pcr_model <- pcr(int_rate ~ . , data = train_dataset, scale=T, validation="CV")
summary (pcr_model)
validationplot(pcr_model, val.type = "MSEP")
```
The lowest cross-validation error occurs when M = 8 component are used. 77.79% of the variation (or information) contained in the predictors are captured by 8 principal components. So compute the test MSE as follows.
```{r pcr_prediction}
pcr_predictions <- predict(pcr_model, test_dataset, ncomp = 8)
pcr_mse <- mean((test_dataset$int_rate - pcr_predictions)^2)
pcr_rmse <- sqrt(mean((test_dataset$int_rate - pcr_predictions)^2))
pcr_mse
```

## PLS model
```{r pls_model_interest_rates}
pls_model <- plsr(int_rate ~ . , data = train_dataset, scale=T, validation="CV")
summary (pls_model)
validationplot(pls_model, val.type = "MSEP")
```
The lowest cross-validation error occurs when M = 8 component are used, after M = 8 the error reduces marginally. 65.72 % of the variation (or information) contained in the predictors are captured by 8 principal components. So compute the test MSE as follows.
```{r, pls_prediction}
pls_predictions <- predict(pls_model, test_dataset, ncomp = 8)
pls_mse <- mean((test_dataset$int_rate  - pls_predictions)^2)
pls_rmse <- sqrt(mean((test_dataset$int_rate  - pls_predictions)^2))
pls_mse
```


  

## Boosting 
  Changed the dataset size due to system constraints
```{r, boosting}
train_dataset_mini <- train_dataset[1:1000,]
test_dataset_mini <- test_dataset[(1:1000),]

pows <- seq(-10, -0.2, by = 0.1)
lambdas <- 10^pows
training_errors <- rep(NA, length(lambdas))


for (i in 1:length(lambdas)) {
  boosting_model <- gbm(int_rate ~ . , data = train_dataset_mini, distribution = "gaussian", 
                       n.trees = 1000, shrinkage = lambdas[i])
  
  training_predictions <- predict(boosting_model, train_dataset_mini, n.trees = 1000)
  training_errors[i] <- mean((training_predictions - train_dataset_mini$int_rate)^2)
}

plot(lambdas, training_errors, xlab = "Shrinkage Values", ylab = "Training set MSE", type = "b", pch = 20)
```


```{r, boosting_plot, message=FALSE}
test_errors <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
  boosting_model <- gbm(int_rate ~ . , data = train_dataset_mini, distribution = "gaussian", 
                       n.trees = 1000, shrinkage = lambdas[i])
  
  test_predictions <- predict(boosting_model, test_dataset_mini, n.trees = 1000)
  test_errors[i] <- mean((test_predictions - test_dataset_mini$int_rate)^2)
}

plot(lambdas, test_errors, xlab = "Shrinkage Values", ylab = "Training set MSE", type = "b", pch = 20)
min(test_errors)
boosting_min_test_err <- min(test_errors)
boosting_min_test_err_at <- lambdas[which.min(test_errors)]
```

Both regression approaches lm and lasso have higher MSE compared to that of boosting.

## Bagging
```{r, 10g_apply_bagging}
random_forest_model <- randomForest(int_rate ~ . , data = train_dataset_mini, ntree = 500, mtry = ncol(train_dataset_mini)-1)
random_forest_predictions <- predict(random_forest_model, test_dataset_mini)

random_forest_test_mse <- mean((random_forest_predictions - test_dataset_mini$int_rate)^2)
random_forest_test_mse
```

Test MSE for bagging is `r random_forest_test_mse` which is better than `r boosting_min_test_err` which is best MSE from boosting


Compare R2 values for various models
```{r model_comparison}
lm_test_r2 <- (1 - (lm_mse/test_interest_mse))
ridge_test_r2 <- (1 - (ridge_mse/test_interest_mse))
lasso_test_r2 <- (1 - (lasso_mse/test_interest_mse))
pcr_test_r2 <- (1 - (pcr_mse/test_interest_mse))
pls_test_r2 <- (1 - (pls_mse/test_interest_mse))
boosting_min_test_err_r2 <- (1 - (boosting_min_test_err/test_interest_mse))
random_forest_r2 <- (1 - (random_forest_test_mse/test_interest_mse))

cat("R square with linear model : ", lm_test_r2, "\n")
cat("R square with ridge model :  ", ridge_test_r2, "\n")
cat("R square with lasso model :  ", lasso_test_r2, "\n")
cat("R square with pcr :          ", pcr_test_r2, "\n")
cat("R square with pls :          ", pls_test_r2, "\n")
cat("R square with boosting :     ", boosting_min_test_err_r2, "\n")
cat("R square with random forest :", random_forest_r2, "\n")

barplot(c(lm_test_r2, ridge_test_r2, lasso_test_r2, pcr_test_r2, pls_test_r2, boosting_min_test_err_r2, random_forest_r2),
        names.arg = c("LM", "Ridge", "Lasso", "PCR", "PLS", "Boosting", "RandomForest"))

```

  All models have R Square values near to 0.6. All models predict interest rate with high accuracy, pcr has less accuracy than others.


# Unspervised Learning - PCA
```{r, unspervised_learning_pca}
ds_lc_pca <- ds_lc_after_correlation
ds_lc_pca = subset(ds_lc_pca, select = -c(is_acct_delinquent,pub_rec, total_rec_late_fee, recoveries, collection_recovery_fee, acc_now_delinq,
                                          num_tl_30dpd,num_tl_90g_dpd_24m))
ds_lc_pca_subset <- sample(nrow(ds_lc), 1000)
ds_lc_pca = ds_lc_pca[ds_lc_pca_subset, ]
str(ds_lc_pca)
pr.out <- prcomp (ds_lc_pca, scale =TRUE)
names(pr.out)
pr.out$center
pr.out$scale
pr.out$rotation
biplot(pr.out)
```

```{r,  unspervised_learning_pca_plot}
pr.out$rotation=-pr.out$rotation
pr.out$x=-pr.out$x
biplot (pr.out , scale =0)
pr.var =pr.out$sdev ^2
pve=pr.var/sum(pr.var )
pve
plot(pve , xlab="Principal Component ", ylab="Proportion of Variance Explained ", ylim=c(0,1) ,type="b")
plot(cumsum (pve ), xlab="Principal Component ", ylab ="Cumulative Proportion of Variance Explained ", ylim=c(0,1) , type="b")
```

```{r,  unspervised_learning_pca_bar_chart}
biplot (pr.out , scale =0)
fviz_eig(pr.out, addlabels = TRUE, ylim = c(0, 50))
```

```{r, pca_outpur}
pr.out
```

```{r, pca_csv_output}
pr.out$rotation[1:21,1:5]
write.csv(pr.out$rotation[1:21,1:5], file = "data/pca_output.csv", row.names=FALSE)
```

Based on the weights of variables across 5 components, here are the composition of variables across five components, in each of these componenets variables listed below are correlated with each other

PC1 => total_pymnt, num_rev_accts, term, open_acc, total_acc, annual_inc,revol_bal, tot_hi_cred_lim, total_rec_int, out_prncp, installment, loan_amnt

PC2 => inq_last_6mths, tot_hi_cred_lim,open_acc, total_acc, num_rev_accts, total_rec_int, int_rate,out_prncp, out_prncp_inv, loan_amnt, installment

PC3 => total_acc,total_rec_int,delinq_2yrs,dti,inq_last_12m,int_rate,fico_range_high,last_fico_range_high

PC4 => delinq_2yrs,dti,revol_bal, inq_last_12m, inq_last_6mths, total_pymnt, fico_range_high

PC5 => annual_inc,tot_hi_cred_lim, delinq_2yrs,total_acc, total_rec_int, num_rev_accts, total_pymnt, fico_range_high, open_acc, home_ownership, last_fico_range_high,dti



```{r,  unspervised_learning_kmean}
ds_lc_kmean <- ds_lc_after_correlation
ds_lc_kmean = subset(ds_lc_kmean, select = -c(is_acct_delinquent,pub_rec, total_rec_late_fee, recoveries, collection_recovery_fee, acc_now_delinq,
                                          num_tl_30dpd,num_tl_90g_dpd_24m))
ds_lc_kmean_subset <- sample(nrow(ds_lc_kmean), 2000)
ds_lc_kmean = ds_lc_kmean[ds_lc_kmean_subset, ]
ds_lc_kmean_scaled <- as.data.frame(scale(ds_lc_kmean))
```

```{r, unspervised_learning_kmean_cluster_size}
set.seed (12345)
k2 <- kmeans(ds_lc_kmean_scaled, centers = 2, nstart = 25)
k3 <- kmeans(ds_lc_kmean_scaled, centers = 3, nstart = 25)
k4 <- kmeans(ds_lc_kmean_scaled, centers = 4, nstart = 25)
k5 <- kmeans(ds_lc_kmean_scaled, centers = 5, nstart = 25)
k6 <- kmeans(ds_lc_kmean_scaled, centers = 6, nstart = 25)
k7 <- kmeans(ds_lc_kmean_scaled, centers = 7, nstart = 25)
k8 <- kmeans(ds_lc_kmean_scaled, centers = 8, nstart = 25)
k9 <- kmeans(ds_lc_kmean_scaled, centers = 9, nstart = 25)


# plots to compare
p2 <- fviz_cluster(k2, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 2")
p3 <- fviz_cluster(k3, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 3")
p4 <- fviz_cluster(k4, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 4")
p5 <- fviz_cluster(k5, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 5")
p6 <- fviz_cluster(k6, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 6")
p7 <- fviz_cluster(k7, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 7")
p8 <- fviz_cluster(k8, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 8")
p9 <- fviz_cluster(k9, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 9")
p10 <- fviz_cluster(k9, geom = "point",  data = ds_lc_kmean_scaled, ggtheme = theme_minimal()) + ggtitle("k = 10")


grid.arrange(p2, p3, p4, p5,  nrow = 2)
grid.arrange(p6, p7, p8, p9,  nrow = 2)
grid.arrange(p10,  nrow = 2)
```

```{r unspervised_learning_kmean_elbow, message=FALSE}
set.seed(12345)
#Function to compute total within cluster sum of squares 
wss <- function(k) {
  kmeans(ds_lc_kmean_scaled, k, nstart = 25, iter.max = 10)$tot.withinss
}

#Compute and plot the within sum of squares (wss) for k = 1 to k = 10
k.values <- 1:15

#Extract wss for 2 - 10 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
     type = "b", pch = 19, frame = FALSE,
     xlab = "Number of clusters K",
     ylab = "Total within clusters sum of squares")

set.seed(1234)
fviz_nbclust(ds_lc_kmean_scaled, kmeans, method = "wss")
```

```{r Gap_Statistic_Method_optimal_clusters }
set.seed(12345)
library(cluster)
gap_stat <- clusGap(ds_lc_kmean_scaled, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
```

Based on the visualization abd GAP statistic method 2 or 3 cluster seem to be of optimal size. 3 clusters seems to be providing better classification based on the visualization.

```{r, unspervised_learning_kmean_asign_cluster}
ds_lc_kmean$cluster <- k3$cluster
print(k3)
```

```{r, unspervised_learning_kmean_final_cluster_viz}
fviz_cluster(k3, data = ds_lc_kmean)
```

Descriptive statistics at the cluster level

```{r, kmean_descriptive_stats}
ds_lc_kmean %>%
  group_by(cluster) %>%
  summarise_all("mean")
```





